{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272e366d",
   "metadata": {},
   "source": [
    "Statistics and overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d6cdb",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fedfbc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025_07_17_01\n",
      "\n",
      "2025_07_17_01\n",
      "2025_07_14_15\n",
      "[ 2  1  4  0 10  5  3  9  8  6  7 11]\n",
      "[2 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "months_map = {\n",
    "    \"stycznia\": \"January\",\n",
    "    \"lutego\": \"February\",\n",
    "    \"marca\": \"March\",\n",
    "    \"kwietnia\": \"April\",\n",
    "    \"maja\": \"May\",\n",
    "    \"czerwca\": \"June\",\n",
    "    \"lipca\": \"July\",\n",
    "    \"sierpnia\": \"August\",\n",
    "    \"września\": \"September\",\n",
    "    \"października\": \"October\",\n",
    "    \"listopada\": \"November\",\n",
    "    \"grudnia\": \"December\"\n",
    "}\n",
    "\n",
    "def polish_to_eng(date_string):\n",
    "    for pl_month, en_month in months_map.items():\n",
    "        if pl_month in date_string:\n",
    "            return date_string.replace(pl_month,en_month)\n",
    "    return date_string\n",
    "\n",
    "\n",
    "with open(\"./../data/data_scrapped/interim/flag_date_scrapping.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    dates = [i for i,item in enumerate(lines) if \"last scrapping date\" in item.lower()]\n",
    "    new_data_line=dates[1]+1\n",
    "    print(lines[new_data_line])  # Print the date for verification\n",
    "    new_data=lines[new_data_line]\n",
    "    new_data=new_data[:-1]\n",
    " \n",
    "    old_data_line=dates[0]+1\n",
    "    old_data=lines[old_data_line]\n",
    "    old_data=old_data[:-1]\n",
    "    print(new_data) ############## Print the date for verification\n",
    "    print(old_data)  # Print the date for verification\n",
    "\n",
    "scrapping_date = new_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataframe = pd.read_csv(\"./../data/data_scrapped/reads/\"+new_data+\".csv\")\n",
    "\n",
    "dataframe = dataframe.drop_duplicates()\n",
    "dataframe = dataframe.drop(\n",
    "    columns=[\n",
    "        \"ID\",\n",
    "        \"Title\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "dataframe[\"Refreshed\"]=dataframe[\"Location\"].astype(str).apply(lambda x: True if \"Od\" in x else False)\n",
    "\n",
    "dataframe[[\"Location\", \"Date\"]] = dataframe[\"Location\"].str.extract(r\"^(.*?)(\\d.*)$\")\n",
    "dataframe[\"Location\"] = dataframe[\"Location\"].str.split(\"-\").str[0].str.strip()\n",
    "\n",
    "dataframe[\"Negotiations\"] = dataframe[\"Price\"].str.contains(\"do\", na=False)\n",
    "dataframe[\"Price\"] = dataframe[\"Price\"].astype(str).str.replace(\",\",\".\",regex=False)\n",
    "dataframe[\"Price\"] = dataframe[\"Price\"].str.split(\" zł\").str[0].str.strip()\n",
    "\n",
    "dataframe[\"Price\"] = dataframe[\"Price\"].str.split(\" złdo\").str[0].str.strip()\n",
    "dataframe[\"Price\"] = dataframe[\"Price\"].astype(str).str.replace(\" zł\", \"\", regex=False)\n",
    "# dataframe[\"Negotiations\"] = dataframe[\"Price\"].str.contains(\n",
    "#     r\"[a-zA-Z]\", regex=True, na=False\n",
    "# )\n",
    "# dataframe[\"Price\"]=dataframe[\"Price\"].str.replace(r'[^0-9]',\"\",regex=True)\n",
    "# dataframe[\"Price\"]=pd.to_numeric(dataframe[\"Price\"],errors=\"coerce\")\n",
    "\n",
    "dataframe[\"Area\"] = dataframe[\"Area\"].str.split(\"m²\").str[0].str.strip()\n",
    "dataframe[\"Area\"] = dataframe[\"Area\"].astype(str).str.replace(\"m²\", \"\", regex=False)\n",
    "dataframe[\"Area\"] = dataframe[\"Area\"].astype(str).str.replace(\",\",\".\",regex=False)\n",
    "dataframe[\"Area\"]=pd.to_numeric(dataframe[\"Area\"],errors=\"coerce\")\n",
    "\n",
    "mask3 = (\n",
    "    dataframe[\"Type_of_Agreement\"].isin([\"sprzedaz\"])\n",
    "    & dataframe[\"Pets\"].isnull()\n",
    ")\n",
    "dataframe.loc[mask3, \"Pets\"] = \"yes\"\n",
    "dataframe[\"Pets\"] = dataframe[\"Pets\"].fillna(\"no\")\n",
    "\n",
    "mask4 = (\n",
    "    dataframe[\"Type_of_Agreement\"].isin([\"sprzedaz\"])\n",
    "    & (dataframe[\"Parking_Space\"].isnull()) & (dataframe[\"Dwelling_Type\"].isin([\"detached_house\", \"terraced_house\"]))  \n",
    ")\n",
    "\n",
    "dataframe.loc[mask4, \"Parking_Space\"] = \"yes\"\n",
    "\n",
    "dataframe[\"Parking_Space\"] = dataframe[\"Parking_Space\"].fillna(\"no\")\n",
    "dataframe[\"Parking_Space\"] = (\n",
    "    dataframe[\"Parking_Space\"].astype(str).str.replace(\"lack\", \"no\", regex=False)\n",
    ")\n",
    "\n",
    "dataframe[\"Furnishing\"] = dataframe[\"Furnishing\"].fillna(\"no\")\n",
    "\n",
    "mask = (\n",
    "    dataframe[\"Dwelling_Type\"].isin([\"terraced_house\", \"detached_house\"])\n",
    "    & dataframe[\"Level\"].isnull()\n",
    ")\n",
    "dataframe.loc[mask, \"Level\"] = \"0\"\n",
    "\n",
    "mask_2 = (\n",
    "    dataframe[\"Dwelling_Type\"].isin([\"terraced_house\", \"detached_house\", \"tenement\"])\n",
    "    & dataframe[\"Elevator\"].isnull()\n",
    ")\n",
    "dataframe.loc[mask_2, \"Elevator\"] = \"no\"\n",
    "\n",
    "\n",
    "\n",
    "dataframe = dataframe.dropna(subset=[\"Seller\", \"Dwelling_Type\", \"Rooms_Number\"])\n",
    "\n",
    "dataframe[\"Pets\"]=dataframe[\"Pets\"].str.lower().map({\"yes\":True,\"no\":False})\n",
    "dataframe[\"Furnishing\"]=dataframe[\"Furnishing\"].str.lower().map({\"yes\":True,\"no\":False})\n",
    "dataframe[\"Elevator\"]=dataframe[\"Elevator\"].str.lower().map({\"yes\":True,\"no\":False})\n",
    "\n",
    "\n",
    "\n",
    "# Levels to numerics\n",
    "dataframe[\"Level\"] = dataframe[\"Level\"].astype(str).str.replace(\"10+\", \"11\")\n",
    "dataframe[\"Level\"] = dataframe[\"Level\"].astype(str).str.replace(\"nan\", \"\")\n",
    "dataframe[\"Level\"]=pd.to_numeric(dataframe[\"Level\"],errors=\"coerce\")\n",
    "dataframe[\"Level\"]=dataframe[\"Level\"].fillna(-1).astype(int)\n",
    "dataframe.loc[(dataframe[\"Level\"] == -1) & (dataframe[\"Elevator\"]==1),\"Level\"]=1\n",
    "dataframe.loc[(dataframe[\"Level\"]==-1)&(dataframe[\"Dwelling_Type\"]==\"tenement\"),\"Level\"]=4\n",
    "dataframe.loc[(dataframe[\"Level\"]==-1),\"Level\"] = 4\n",
    "print(dataframe[\"Level\"].unique())\n",
    "\n",
    "\n",
    "dataframe[\"Rooms_Number\"]=dataframe[\"Rooms_Number\"].str.replace(\"4+\",\"4\",regex=False)\n",
    "dataframe[\"Rooms_Number\"]=pd.to_numeric(dataframe[\"Rooms_Number\"],errors=\"coerce\")\n",
    "print(dataframe[\"Rooms_Number\"].unique())\n",
    "\n",
    "#To do date\n",
    "\n",
    "# Hour to day of the scrapping\n",
    "dataframe[\"Date\"]=dataframe[\"Date\"].astype(str).apply(lambda x: scrapping_date if \":\" in x else x)\n",
    "dataframe[\"Date\"]=dataframe[\"Date\"].apply(polish_to_eng)\n",
    "dataframe[\"Date\"]=pd.to_datetime(dataframe[\"Date\"], dayfirst=True,errors='coerce').dt.date\n",
    "\n",
    "\n",
    "# all builings in Poland, which have more than 4 levels need to have elevator\n",
    "\n",
    "# W końcu to jebane elevator\n",
    "\n",
    "dataframe[\"Elevator\"]=dataframe[\"Elevator\"].fillna(-1).astype(int)\n",
    "dataframe.loc[(dataframe[\"Level\"]>4) &(dataframe[\"Elevator\"]==-1),\"Elevator\"] =1\n",
    "dataframe[\"Elevator\"]=dataframe[\"Elevator\"].replace(-1,0)\n",
    "# print(dataframe.isnull().sum())\n",
    "# print(dataframe.info())\n",
    "\n",
    "\n",
    "\n",
    "#To do : split data by type of agreement, for sale pets all yes, for rent null all no; parking space for sale detached hourse yes, for rent no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06164d8",
   "metadata": {},
   "source": [
    "Number of records count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e00b9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = dataframe.shape[0]\n",
    "\n",
    "with open(\"./../data/data_scrapped/interim/flag_date_scrapping.txt\", \"a\") as f:\n",
    "    f.write(f\"Downloaded records count: {count}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c4c3fb",
   "metadata": {},
   "source": [
    "Older record filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6d3d72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025_07_14_15\n",
      "\n",
      "2025-07-14\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "with open(\"./../data/data_scrapped/interim/flag_date_scrapping.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    print(lines[2])\n",
    "last_scrapping_date = lines[2].strip()#or old_data\n",
    "last_scrapping_date = last_scrapping_date[:-3].replace(\"_\", \"-\")\n",
    "\n",
    "print(last_scrapping_date)\n",
    "# Convert last_scrapping_date to datetime.date for comparison\n",
    "last_scrapping_date_dt = datetime.strptime(last_scrapping_date, \"%Y-%m-%d\").date()\n",
    "dataframe = dataframe[dataframe[\"Date\"] >= last_scrapping_date_dt]\n",
    "cities = dataframe[\"City\"].unique()\n",
    "\n",
    "with open(\"./../data/data_scrapped/interim/flag_date_scrapping.txt\", \"a\") as f:\n",
    "    f.write(f\"Records count after filtering: {dataframe.shape[0]}\\n\")\n",
    "    for city in cities:\n",
    "        count_city = dataframe[dataframe[\"City\"] == city].shape[0]\n",
    "        f.write(f\"City: {city}, Records count: {count_city}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aab135",
   "metadata": {},
   "source": [
    "Send e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603fb97",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m./../data/data_scrapped/interim/flag_date_scrapping.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     13\u001b[39m     lines = f.readlines()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     subject = lines[\u001b[38;5;28mint\u001b[39m(new_data_line)].strip(), \u001b[43mlines\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_data_line\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m.strip()\n\u001b[32m     15\u001b[39m     subject_data = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(subject)  \u001b[38;5;66;03m# Join the subject lines into a single string\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Collect city records for the body\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "from email.mime.text import MIMEText\n",
    "import base64\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "n = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "with open(\"./../data/data_scrapped/interim/flag_date_scrapping.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    subject = lines[int(new_data_line)].strip(), lines[int(new_data_line+2)].strip()\n",
    "    subject_data = \" \".join(subject)  # Join the subject lines into a single string\n",
    "    # Collect city records for the body\n",
    "    body_lines = [lines[i].strip() for i in range(int(new_data_line+1), int(len(lines)))]\n",
    "    body_data = \"\\n\\n\".join(body_lines)\n",
    "    body_data = f\"{body_data}\\n\\n{n}\"  # Add timestamp to the body\n",
    "    print(subject_data)  # Print the subject for verification\n",
    "    print(body_data)\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/gmail.send']\n",
    "\n",
    "def get_gmail_credentials():\n",
    "    creds = None\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('cred.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "def create_message(to_email, from_email, subject, body):\n",
    "    message = MIMEText(body)\n",
    "    message['to'] = to_email\n",
    "    message['from'] = from_email\n",
    "    message['subject'] = subject\n",
    "    raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
    "    return {'raw': raw_message}\n",
    "\n",
    "def send_email_via_gmail_api(subject, body, to_email, from_email):\n",
    "    creds = get_gmail_credentials()\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "    message = create_message(to_email, from_email, subject, body)\n",
    "    sent_message = service.users().messages().send(userId='me', body=message).execute()\n",
    "    print(f\"Message sent! ID: {sent_message['id']}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "send_email_via_gmail_api(\n",
    "    subject=subject_data,\n",
    "    body=body_data,\n",
    "    to_email=\"oktawiusz.receiver@gmail.com\",\n",
    "    from_email=\"oktawiusz.sender@gmail.com\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e18b045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Link    Price  \\\n",
      "3727  https://www.olx.plhttps://www.otodom.pl/pl/ofe...  999 000   \n",
      "3740  https://www.olx.plhttps://www.otodom.pl/pl/ofe...  995 000   \n",
      "1910  https://www.olx.pl/d/oferta/6-pokoi-i-pietro-p...  993 000   \n",
      "3642  https://www.olx.plhttps://www.otodom.pl/pl/ofe...  990 000   \n",
      "2222  https://www.olx.plhttps://www.otodom.pl/pl/ofe...  989 000   \n",
      "3682  https://www.olx.pl/d/oferta/nowoczesne-mieszka...  980 000   \n",
      "3883  https://www.olx.plhttps://www.otodom.pl/pl/ofe...  980 000   \n",
      "3676  https://www.olx.plhttps://www.otodom.pl/pl/ofe...  978 500   \n",
      "3608  https://www.olx.plhttps://www.otodom.pl/pl/ofe...  975 000   \n",
      "3665  https://www.olx.plhttps://www.otodom.pl/pl/ofe...  950 000   \n",
      "\n",
      "                  Location   Area      City       Scrapping_Date  \\\n",
      "3727     Warszawa, Ursynów  63.00  warszawa  2025-07-17 01:58:13   \n",
      "3740       Warszawa, Praga  64.58  warszawa  2025-07-17 01:58:13   \n",
      "1910  Wrocław, Śródmieście  82.78   wroclaw  2025-07-17 01:56:56   \n",
      "3642    Warszawa, Targówek  70.00  warszawa  2025-07-17 01:58:10   \n",
      "2222               Wrocław  66.00   wroclaw  2025-07-17 01:57:08   \n",
      "3682   Warszawa, Białołęka  70.71  warszawa  2025-07-17 01:58:12   \n",
      "3883    Warszawa, Targówek  54.00  warszawa  2025-07-17 01:58:18   \n",
      "3676     Warszawa, Mokotów  61.00  warszawa  2025-07-17 01:58:12   \n",
      "3608       Warszawa, Ursus  64.14  warszawa  2025-07-17 01:58:10   \n",
      "3665       Warszawa, Ursus  78.00  warszawa  2025-07-17 01:58:12   \n",
      "\n",
      "     Type_of_Agreement Dwelling_Type  Elevator  Furnishing  Level  \\\n",
      "3727          sprzedaz         block         1        True      6   \n",
      "3740          sprzedaz         block         0        True      0   \n",
      "1910          sprzedaz      tenement         0        True      1   \n",
      "3642          sprzedaz         block         0       False      2   \n",
      "2222          sprzedaz      tenement         0        True      3   \n",
      "3682          sprzedaz         block         0        True      1   \n",
      "3883          sprzedaz         block         0        True      4   \n",
      "3676          sprzedaz         block         0       False      3   \n",
      "3608          sprzedaz     apartment         0       False      2   \n",
      "3665          sprzedaz         block         1       False      5   \n",
      "\n",
      "     Parking_Space  Pets  Rooms_Number      Seller  Refreshed        Date  \\\n",
      "3727            no  True             3  developers      False  2025-07-15   \n",
      "3740            no  True             3  developers      False  2025-07-14   \n",
      "1910            no  True             4     private       True  2025-07-14   \n",
      "3642            no  True             4  developers      False  2025-07-15   \n",
      "2222            no  True             3     private       True  2025-07-15   \n",
      "3682            no  True             4     private      False  2025-07-15   \n",
      "3883            no  True             3     private      False  2025-07-14   \n",
      "3676            no  True             3  developers       True  2025-07-15   \n",
      "3608            no  True             3  developers      False  2025-07-14   \n",
      "3665            no  True             3  developers      False  2025-07-15   \n",
      "\n",
      "      Negotiations  \n",
      "3727         False  \n",
      "3740         False  \n",
      "1910         False  \n",
      "3642         False  \n",
      "2222         False  \n",
      "3682          True  \n",
      "3883         False  \n",
      "3676         False  \n",
      "3608         False  \n",
      "3665         False  \n"
     ]
    }
   ],
   "source": [
    "dataframe.to_csv(\"./../data/data_scrapped/reads/\"+new_data+\"_cleaned.csv\", index=False)\n",
    "# print(dataframe[\"Parking_Space\"].unique())\n",
    "print(dataframe.sort_values(by=\"Price\", ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
